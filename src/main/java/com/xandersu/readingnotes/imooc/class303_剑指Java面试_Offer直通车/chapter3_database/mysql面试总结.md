架构
索引
锁
语法
理论范式

设计一个数据库
|-----------------------|
|程序实例|
|-----------------------|
|存储模块（文件系统）|
|------------------------|
程序实例：
存储管理(块、页加载到内存)：数据的逻辑关系转换成物理存储关系。
缓存机制：优化执行效率的缓存模块
SQL解析：解析sql语句
日志管理（binlog）：记录操作日志
权限划分：多用户管理
容灾机制：灾难恢复
索引模块：优化数据查询效率
锁模块：使数据库支持并发操作
索引模块
https://www.mysqlzh.com/doc/215/427.html
https://blog.csdn.net/qq_32483145/article/details/80191323
https://blog.csdn.net/qq_28584889/article/details/88778741
https://blog.csdn.net/voidccc/article/details/40077329
索引（Index）是帮助MySQL高效获取数据的数据结构。MyISAM和Innodb都使用了B+树这种数据结构做为索引。
索引分为聚簇索引和非聚簇索引两种，在一个表中只能有一个聚集索引，一般以主键作为聚集索引，而非聚集索引可以有多个。

## 为什么要使用索引
快速查询数据
避免全表扫描
减少了服务器需要扫描的数据量
避免排序和临时表
将随机I/O变为顺序I/O

什么样的信息能成为索引
主键、唯一键以及普通键

# 索引的数据结构

## 二叉树
- b tree
- b+ tree（mysql主要）
- hash结构
- 二叉树

查询O(logn) 可能退化成链表 O(n)

## B-Tree

- 根节点至少包括两个孩子
- 树中每个节点最多包含有m个孩子()m>=2)
- 除根节点和叶节点外，其他每个节点至少有ceil(m/2)个孩子
- 所有叶子节点位于同一层
- ...

## B+-Tree

B+-Tree是B树的变体，其定义基本与B树相同，除了：
- 非叶子节点的子树指针与关键字个数相同
- 非叶子节点的子树指针p[i]指向关键字值(K[i],K[i+1])的子树
- 非叶子节点仅用做索引，数据都保存在叶子节点中
- 所有叶子节点均有一个链指针指向下一个叶子节点

B+树更适合用作存储索引
- B+树的磁盘读写代价更低：内部结构并没有指向关键字具体信息的指针（不存放数据，只存放索引信息），内部节点比B树小，如果把所有同一个内部节点的关键字存放在同一个盘块中，盘块所能容纳的关键字数量越多，一次性读入内存中的需要查找的关键字也越多，相对IO对读写次数降低。
- B+树的查询效率更稳定：内部节点并不是最终指向文件内容节点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。O（logn）
- B+树更有利于对数据库的扫描：B树在提高了IO性能的同时并没有解决元素遍历的效率低下的问题。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。B+树更加适合在区间查询的情况。

单个节点可以存储更多的数据，减少I/O的次数。
查找性能更稳定，因为都是要查找到叶子结点。
叶子结点形成了有序链表，便于查询。

### B+ Tree索引优点

  ①.全值匹配：指的是和索引中所有列进行匹配。假设以(姓，名，出生日期)三个数据项建立复合索引，那么可以查找姓名为张三，出生日期在2000-12-12的人 
  ②.匹配最左前缀：假设以(姓，名，出生日期)三个数据项建立复合索引，可以查找所有姓张的人 
  ③.匹配列前缀：假设有姓为司徒，司马的人，我们也可以查找第一列的前缀部分，如查找所有以司开头的姓的人 
  ④.匹配范围值：可以查找所有在李和张之间的姓的人，注意范围查询只在复合索引的优先排序的第一列。（假设姓名按照拼音排序） 
  ⑤.精确匹配前面列并范围匹配后一列：可以查找姓李并出生日期在2000-12-12之后的人或姓名为张三并出生日期在2000-12-12之后的人，注意范围第一个范围查询后面的列无法再使用索引查询 
  ⑥.只访问索引的查询：即查询只需访问索引，而无需访问数据行。（此时应想到索引中的覆盖索引）

### B+ Tree索引缺点

  ①.如果不是按照索引的最左列开始查找，则无法使用索引。如无法查找名为龙的人，也无法查找在2000-12-12之后出生的人，当然也无法查找姓中以龙结尾的人（注意为和含有的区别） 
  ②.不能跳过索引中的列：无法查找姓李并在2000-12-12之后出生的人 
  ③.如果查询中包括某个列的范围查询，则其右边所有列都无法使用索引优化查询

Hash索引缺点

- 仅仅能满足 = IN 不能使用范围查询
- 无法被用来避免数据的排序操作
- 不能利用部分索引键查询
- 不能避免表扫描
- 遇到大量Hash值相等的情况后性能并不一定比B+树索引高

密集索引和稀疏索引的区别

对于聚簇索引存储来说，行数据和主键B+树存储在一起，辅助键B+树只存储辅助键和主键的值，主键和非主键B+树几乎是两种类型的树。
对于非聚簇索引存储来说，主键B+树在叶子节点存储指向真正数据行的指针，而非主键。
- 密集索引文件中的每个搜索码值都对应一个索引值
- 稀疏索引文件只为索引码的某些值建立索引项

### innodb：

若有一个主键，则该主键作为密集索引
若没有主键被定义，该表第一个唯一非空索引代替
都不满足，则innodb内部会生成一个隐藏的主键作为密集索引（这个字段长度为6个字节，类型为长整形）
稀疏索引的叶子节点并不存储行数据的的物理地址，而是存储该行的主键值，所以稀疏索引包含了两次查找，一次是查找次级索引自身，再查找主键
InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上

where id = 14"这样的条件查找主键，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。若对Name列进行条件搜索，则需要两个步骤：
第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。
第二步使用主键在主索引B+树种再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。

所以Innodb不建议使用过长的主键，否则会使辅助索引变得过大。建议使用自增的字段作为主键

###  MyISM使用的是非聚簇索引

主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。

### 聚簇索引的优势：

1 由于行数据和叶子节点存储在一起，这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。
2 辅助索引使用主键作为"指针" 而不是使用地址值作为指针的好处是，减少了当出现行移动或者数据页分裂时辅助索引的维护工作，使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个"指针"。也就是说行的位置（实现中通过16K的Page来定位，后面会涉及）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。

### Page结构

Page是整个InnoDB存储的最基本构件，也是InnoDB磁盘管理的最小单位，与数据库相关的所有内容都存储在这种Page结构里。Page分为几种类型，常见的页类型有数据页（B-tree Node）Undo页（Undo Log Page）系统页（System Page） 事务数据页（Transaction System Page）等。单个Page的大小是16K（编译宏UNIV_PAGE_SIZE控制），每个Page使用一个32位的int值来唯一标识，这也正好对应InnoDB最大64TB的存储容量（16Kib * 2^32 = 64Tib）。

Page的头部保存了两个指针，分别指向前一个Page和后一个Page，头部还有Page的类型信息和用来唯一标识Page的编号。双向链表的结构。

## 如何定位并优化慢查询sql

- 根据慢日志定位慢查询sql
- 使用explain等工具分析sql
- 修改sql或者尽量让sql走索引

联合索引的最左匹配原则的成因
最左匹配原则

## 索引是建立的越多越好吗

数据量小的表不需要建立索引，建立会增加额外的索引开销
数据变更需要维护索引，因此更多的索引意味着更多的维护成本
更多的索引意味着也需要更多的空间

## 如何定位并优化慢查询sql

- 根据慢日志定位慢查询sql
- 使用explain等工具分析sql
- 修改sql或者尽量让sql走索引
- 根据慢日志定位慢查询sql

show variables like '%quer%';
slow_query_log  OFF
slow_query_log_file /usr/local/mysql/data/xxx-slow.log
long_query_time 1.0000

//有一条sql比较慢就+1
show status like '%slow_queries%';
slow_queries    0

set global slow_query_log = on; --打开慢查询日志
set global long_query_time = 1; --设置慢查询时间1秒
Explain关键字
explain select * from XXX order by XXX

### type

system>const>eq_ref>ref>fulltext>ref_or_null>index_merge>unique_subquery>index_subquery>range>index>all
   快到慢  index和all出现代表需要优化

### extra

出现Using filesort和Using tempoaary代表mydql无法使用索引，影响效率。要优化
Using filesort    说明MySQL会对结果使用一个外部索引排序，而不是从表里按索引次序读到相关内容。可能在内存或者磁盘上排序。MySQL中无法利用索引完成的排序称为“文件排序”。
Using temporary   表示MySQL在对查询结果排序时使用临时表。常见于排序order by 和分组查询group by

force index (primary)，use index ，ignore index
select count(*) from XXX force index (primary); 
强制使用主键(使用主键不一定最快，查询优化器决定用哪个索引，但具体情况具体分析) 

### 索引额外问题之最左匹配原则的成因

1. 最左匹配原则，非常重要，MySQL会一直向右匹配知道遇到范围查询(>、<、between、like)就停止匹配，比如a = 3 and b = 4 and c > 5 and d = 6
如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，abd的顺序可以任意调整。
2. =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，MySQL查询优化器会帮你优化城索引可以识别的形式。
mysql索引最左匹配原则的理解

b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道第一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。

### 索引额外问题之索引是建立越多越好吗

数据量小的表不需要建立索引，建立会增加额外的索引开销
数据变更需要维护索引，因此更多的索引意味着更多的维护成本
更多的索引意味着也需要更多的空间

### MyISAM与InnoDB关于锁方面的区别是什么

https://www.cnblogs.com/ahguSH/p/7246552.html?utm_source=itdadao&utm_medium=referral
https://www.cnblogs.com/itfenqing/p/6802497.html

MyISAM默认用表级锁，不支持行级锁

InnoDB默认用行级锁，也支持表级锁

InnoDB在sql没有走索引的时候用表级锁，sql用索引时用行级锁、gap锁。

MyISAM引擎在增删改少的系统，性能好于InnoDB。

### MyISAM适合的场景

频繁执行全表count语句
对数据进行增删改的频率不高，查询非常频繁
没有事务

### InnoDB适合的场景

数据增删改查都相当频繁
可靠性要求高，要求支持事务

## 数据库锁的分类

锁的粒度：表级锁、行级锁、页级锁
锁级别：共享锁（LOCK IN SHARE MODE）、排它锁（FOR UPDATE）
加锁的方式：自动锁、显式锁
操作划分：DML锁、DDL锁
使用方式划分：乐观锁、悲观锁

select语句默认不会加任何锁类型

update,delete,insert都会自动给涉及到的数据加上排他锁
1. 共享锁SELECT ... LOCK IN SHARE MODE
2. 排它锁SELECT  …  FOR UPDATE

### InnoDB的行锁实现方式

1. InnoDB行锁是通过给索引上的索引项加锁来实现的， InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！
2. MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁等待的
3. 当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。
4. 即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。

### 间隙锁

当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。

### InnoDB的表锁

1.LOCK TABLES tb_name WRITE;//当前会话对表tb_name可读可写,其余会话对表tb_name不可读不可写
2.LOCK TABLES tb_name READ;//当前会话对表tb_name可读不可写,其余会话对表tb_name可读不可写
3.你需要一次锁定更新的表

LOCK TABLES tb1_name WRITE;
在锁定过程中,你可以读tbl2_name,当你需要更新tbl2_name,你将得到一个表无法锁定的错误

4.innodb的表锁,开始事务时会自动释放表锁,所以begin;或set autocommit=0;等命令应该在lock tables的前面.
1.使用LOCK TABLES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层──MySQL Server负责的，仅当autocommit=0、innodb_table_locks=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，MySQL Server也才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁。有关死锁，下一小节还会继续讨论。

2.在用LOCK TABLES对InnoDB表加锁时要注意，要将AUTOCOMMIT设为0，否则MySQL不会给表加锁；事务结束前，不要用UNLOCK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK并不能释放用LOCK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁。正确的方式见如下语句：

SET AUTOCOMMIT=0;
LOCK TABLES t1 WRITE, t2 READ, ...;
[do something with tables t1 and t2 here];
COMMIT;
UNLOCK TABLES;

### 在应用中避免死锁的方法

发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodb_lock_wait_timeout来解决。这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。

1. 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。
2. 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。
3. 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。
4. 前面讲过，在REPEATABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT...FOR UPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可避免问题
5. 当隔离级别为READ COMMITTED时，如果两个线程都先执行SELECT...FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第1个线程提交后，第2个线程会因主键重复出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第3个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键重复异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁



### InnoDB可重复读隔离级别下如何避免幻读

https://www.jianshu.com/p/7e967d291c24
http://mysql.taobao.org/monthly/2018/03/01/

- 表象：快照读（非阻塞读） --伪MVCC（多版本并发控制）;
- 内在：next-key锁（行锁+gap锁）

### 什么是当前读和快照读

当前读：select ... lock in share mode,select ... for update、update,delete,insert
当前读是加了锁的增删改查，无论共享锁还是排他锁都是当前读。读取的是记录的最新版本，并且读取之后还要保证其他并发事务不能修改当前记录，对读取的记录加锁。
快照读：不在串行化下不加锁的非阻塞读。

### RC、RR级别下的InnoDB的非阻塞读如何实现

- 数据行里的
DB_TRX_ID（最近一次对本行记录做修改的事务的标示符，事务id）、
DB_ROLL_PTR（回滚指针，写入回滚段rollback segment的undo log日志记录，如果一行记录被更新，则undo log record包含重建该行记录被更新之前内容所必须的信息）、
DB_ROW_ID（行号，包含一个随着新行插入而单调递增的行id，当由innodb自动产生聚集索引时，聚集索引包含行id的值，否则这个行id不会出现再任何索引中）字段
- undo日志：当变更了记录，就会产生undo日志，undo日志存储的是老版的数据，当一个旧的事务需要读取数据时，为了能读取老版本的数据，需要顺着undo链找到满足其可见性的记录。undo log分为两种 insert undo log、update undo log。 insert undo log表示事务对insert新记录产生的，只在事务回滚时需要，并且再事务提交后立即丢弃。update undo log事务对记录进行delete或者update产生，不仅事务回滚时需要，快照读也需要，不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被Purge线程删除。
- read view：做可见性判断，当我们执行快照读select，会针对查询的数据创造出一个readview，来决定当前事务能看到的是哪个版本的数据，有可能当前或者只允许undo log某个版本的数据，遵循一个可见性算法，将要修改的数据的DB_TRX_ID取出来与系统其他活跃事务id作对比，如果大于或者等于这些id，通过DB_ROLL_PTR取出undo log上一层的DB_TRX_ID直到小于这些活跃事务id为止。保证了获取到的数据版本是当前所见的最稳定的版本。

### 为什么没有真正实现MVCC

mvcc多版本控制，读不加锁，读写不冲突，在读多写少，增加并发性能。
并没有实现多版本并存，undolog里内容是串行化的结果，记录事务的过程不属于多版本共存。
next-key真正防止幻读

行锁：对单个行上的锁
Gap锁：间隙锁，锁定一个范围但不包括记录本身。防止同一个事务两次当前读出现幻读。

RR、串行化，都支持间隙锁。

### 对主键索引或者唯一索引会用Gap锁吗

如果where条件全部命中，则不会用Gap锁，只会加记录锁。
如果where条件部分命中或全不命中，则会加Gap锁

Gap锁用在非唯一索引或者不走索引的当前读当中

详细分析MySQL事务日志(redo log和undo log)
https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html

https://www.linuxidc.com/Linux/2018-01/150614.htm
重做日志（redo log）

作用：
　　确保事务的持久性。
　　防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。
内容：
　　物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。
什么时候产生：
　　事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。
什么时候释放：
　　当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。
对应的物理文件：
　　默认情况下，对应的物理文件位于数据库的data目录下的ib_logfile1&ib_logfile2
　　innodb_log_group_home_dir 指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。
　　innodb_log_files_in_group 指定重做日志文件组中文件的数量，默认2
　　关于文件的大小和数量，由一下两个参数配置
　　innodb_log_file_size 重做日志文件的大小。
　　innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认1
其他：
　　很重要一点，redo log是什么时候写盘的？前面说了是在事物开始之后逐步写盘的。
　　之所以说重做日志是在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存，
　　原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M(这里设置的16M),Innodb存储引擎先将重做日志写入innodb_log_buffer中。

　　

然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘
1，Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件。
2，每个事务提交时会将重做日志刷新到重做日志文件。
3，当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件
由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是对于第一种方式，Innodb_log_buffer到重做日志文件是Master Thread线程的定时任务。
因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。
另外引用《MySQL技术内幕 Innodb 存储引擎》（page37）上的原话：
即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。
这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。


回滚日志（undo log）

作用：
　　保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读

内容：
　　逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。

什么时候产生：
　　事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性

什么时候释放：
　　当事务提交之后，undo log并不能立马被删除，
　　而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。

对应的物理文件：
　　MySQL5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认的名称是ibdata，位于数据文件目录中。
　　MySQL5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数
　　如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。
　　关于MySQL5.7之后的独立undo 表空间配置参数如下
　　innodb_undo_directory = /data/undospace/ --undo独立表空间的存放目录
　　innodb_undo_logs = 128 --回滚段为128KB
　　innodb_undo_tablespaces = 4 --指定有4个undo log文件

　　如果undo使用的共享表空间，这个共享表空间中又不仅仅是存储了undo的信息，共享表空间的默认为与MySQL的数据目录下面，其属性由参数innodb_data_file_path配置。
　　

其他：
　　undo是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。
　　默认情况下undo文件是保持在共享表空间的，也即ibdatafile文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的undo信息，全部保存在共享表空间中的。
　　因此共享表空间可能会变的很大，默认情况下，也就是undo 日志使用共享表空间的时候，被“撑大”的共享表空间是不会也不能自动收缩的。
　　因此，mysql5.7之后的“独立undo 表空间”的配置就显得很有必要了。

二进制日志（binlog）：

作用：
　　1，用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
　　2，用于数据库的基于时间点的还原。
内容：
　　逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
　　但又不完全是sql语句这么简单，而是执行的sql语句（增删改）反向的信息，
　　也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。
　　在使用mysqlbinlog解析binlog之后一些都会真相大白。
　　因此可以基于binlog做到类似于Oracle的闪回功能，其实都是依赖于binlog中的日志记录。

什么时候产生：
　　事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
　　这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。
　　因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。
　　这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。

什么时候释放：
　　binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。
　　

对应的物理文件：
　　配置文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定的最大的大小之后，进行滚动更新，生成新的日志文件。
　　对于每个binlog日志文件，通过一个统一的index文件来组织。

　

其他：
　　二进制日志的作用之一是还原数据库的，这与redo log很类似，很多人混淆过，但是两者有本质的不同
　　1，作用不同：redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。
　　2，内容不同：redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，可以简单认为记录的就是sql语句
　　3，另外，两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。

　　关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，
　　MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。 